{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOPOzeAP4jdZqHRPT4FzM/f",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Wachiputi/ACPP/blob/model-ACPP/CommodityPriceProjection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**IMPORTING THE FRAMEWORKS AND TOOLS**"
      ],
      "metadata": {
        "id": "7X_kcorGXfEH"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Yd34_W6wKT7M"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sn\n",
        "import math\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy.random as rnd\n",
        "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
        "import statsmodels.api as sm"
      ],
      "metadata": {
        "id": "YVZZE9J3JVvC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#this line of code is importing three classes from the sklearn (scikit-learn) library in Python. These classes are used for creating custom machine learning models and transformers.\n",
        "from sklearn.base import BaseEstimator,TransformerMixin,RegressorMixin"
      ],
      "metadata": {
        "id": "nv9iJ-8tLG4S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#This line of code sets the random seed to 42 using the rnd.seed() function.\n",
        "#Setting the random seed ensures that the sequence of random numbers generated by the code remains the same every time it's run\n",
        "#making the code's behavior deterministic.\n",
        "\n",
        "rnd.seed(42)"
      ],
      "metadata": {
        "id": "906A9cQGLesJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**LOADING THE DATA**"
      ],
      "metadata": {
        "id": "XS93mKUEMAIz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data1 = pd.read_csv('/content/wfp_food_prices_mwi.csv')\n",
        "data1.head(5)"
      ],
      "metadata": {
        "id": "QcFFEpsjav7s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Drop row at position 0\n",
        "data = data1.drop(data1.index[0])\n",
        "data.head(5)"
      ],
      "metadata": {
        "id": "w-mAbLM2Sdor"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.dropna(inplace=True)"
      ],
      "metadata": {
        "id": "RBgJbGOCelGt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##converting the categorical values to float and data to datetime"
      ],
      "metadata": {
        "id": "zkS4wlopOxtw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert 'date' column to datetime\n",
        "data['date'] = pd.to_datetime(data['date'])\n",
        "\n",
        "# Convert 'price' column to float\n",
        "data['price'] = pd.to_numeric(data['price'])\n",
        "\n",
        "# Convert 'longitude' and 'latitude' columns to float\n",
        "data['longitude'] = pd.to_numeric(data['longitude'])\n",
        "data['latitude'] = pd.to_numeric(data['latitude'])\n",
        "data['usdprice'] = pd.to_numeric(data['usdprice'])\n",
        "\n",
        "# If there are any specific units that need conversion (e.g., from meters to kilometers),\n",
        "# you would need to perform additional operations to convert the values accordingly.\n",
        "\n",
        "# Example:\n",
        "# Convert latitude and longitude from degrees to radians\n",
        "data['longitude'] = data['longitude'].apply(math.radians)\n",
        "data['latitude'] = data['latitude'].apply(math.radians)"
      ],
      "metadata": {
        "id": "I_7fGPs_O131"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.info()"
      ],
      "metadata": {
        "id": "siYoSG1KMQtJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##SHOWS THAT ALL THE DATA IS CATEGORICAL,one of them is  Commodity Let's see what values it contain."
      ],
      "metadata": {
        "id": "iEDXbkenMh5a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data['commodity'].value_counts()"
      ],
      "metadata": {
        "id": "q16GgVfANL8R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#The describe() function in pandas is used to generate descriptive statistics of a DataFrame (data)\n",
        "data.describe()"
      ],
      "metadata": {
        "id": "xfjz1KvFNd9L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#This line of code creates histograms for each numeric column in the DataFrame data. The hist() function in pandas is used to create histograms,\n",
        "#and by specifying bins=50, it divides the range of values into 50 equal-width bins.\n",
        "#The figsize=(15,10) parameter adjusts the size of the resulting figure to be 15 inches wide and 10 inches tall.\n",
        "data.hist(bins=50,figsize=(15,10))"
      ],
      "metadata": {
        "id": "fKw-pgAsORM2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**GETTING THE DATASET**"
      ],
      "metadata": {
        "id": "hekynGUWVSSd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "*  Used Stratified sampling technique\n",
        "*  Defined a new feature price_cat which is income category and used if for sampling\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "-5Fd0tErVg7d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data['price_cat']=np.ceil(data['price']/1.5)\n",
        "data['price_cat'].where(data['price_cat']<5,5.0,inplace=True)"
      ],
      "metadata": {
        "id": "nu5njfA-VR5b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert 'income_cat' column to categorical data type\n",
        "data['price_cat'] = pd.Categorical(data['price_cat'])\n",
        "\n",
        "# Identify classes with low frequencies\n",
        "class_counts = data['price_cat'].value_counts()\n",
        "low_frequency_classes = class_counts[class_counts < 2].index.tolist()\n",
        "\n",
        "# Combine low frequency classes into a single class\n",
        "data['price_cat'] = data['price_cat'].replace(low_frequency_classes, 'Other')\n",
        "\n",
        "# Check the updated distribution of classes\n",
        "print(data['price_cat'].value_counts())\n"
      ],
      "metadata": {
        "id": "BruReLaPZ34q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import StratifiedShuffleSplit"
      ],
      "metadata": {
        "id": "enB0Mmz-Yzpp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "this code is creating a stratified split of the dataset into training and testing sets, ensuring that the distribution of categories in the 'income_cat' column is similar in both sets. This is important for training and evaluating machine learning models to ensure that they generalize well to unseen data."
      ],
      "metadata": {
        "id": "2eByYPGrZKpY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check the indices generated by StratifiedShuffleSplit\n",
        "print(\"Train indices:\", train_index)\n",
        "print(\"Test indices:\", test_index)\n",
        "\n",
        "# Check if the DataFrame contains any data\n",
        "print(\"Data empty?\", data.empty)\n",
        "\n",
        "# Verify column names\n",
        "print(\"Column names in data:\", data.columns)\n",
        "print(\"Is 'price_cat' in columns?\", 'price_cat' in data.columns)\n",
        "\n",
        "# Reset DataFrame index if needed\n",
        "# data.reset_index(inplace=True)\n",
        "\n",
        "# Check for duplicate indices\n",
        "print(\"Duplicates in data:\", data.index.duplicated().any())\n"
      ],
      "metadata": {
        "id": "Tl2pXMUIm1Aq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.reset_index(drop=True, inplace=True)"
      ],
      "metadata": {
        "id": "iEd4lXzMo0J7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#it's dividing the dataset into training and testing sets while ensuring that the proportion of different categories in the 'income_cat' column remains similar in both sets.\n",
        "\n",
        "data['price_cat'] = pd.to_numeric(data['price_cat'], errors='coerce')  # 'coerce' will convert non-numeric values to NaN\n",
        "\n",
        "# Drop rows with NaN values in 'income_cat' column\n",
        "data.dropna(subset=['price_cat'], inplace=True)\n",
        "\n",
        "# Now, perform the Stratified Shuffle Split\n",
        "split = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=42)\n",
        "for train_index, test_index in split.split(data, data['price_cat']):\n",
        "    strat_train_set = data.loc[train_index]\n",
        "    strat_test_set = data.loc[test_index]"
      ],
      "metadata": {
        "id": "4IAp3LhlY4U3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "strat_train_set.drop('price_cat',axis=1,inplace=True)\n",
        "strat_test_set.drop('price_cat',axis=1,inplace=True)\n",
        "\n",
        "#This operation is commonly done after the stratified shuffle split when the column used for stratification (in this case, 'income_cat') is no longer needed for training or testing the model.\n",
        "#Removing this column ensures that the model does not learn any spurious patterns related to this variable during training."
      ],
      "metadata": {
        "id": "M1hg0VmjpWpu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "strat_train_set.to_csv(\"strat_train_set.csv\",index=False)\n",
        "strat_test_set.to_csv(\"strat_test_set.csv\",index=False)\n",
        "\n",
        "#By saving the DataFrames to CSV files, you can store the data in a format that can be easily loaded into various tools and libraries for further analysis, visualization, or modeling.\n",
        "#The index=False argument ensures that the CSV files do not include an additional column for DataFrame indices."
      ],
      "metadata": {
        "id": "pmEJzbtppc_k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Exploratory Data Analysis**"
      ],
      "metadata": {
        "id": "ZCx6qHuQMl5v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data=pd.read_csv('strat_train_set.csv')\n",
        "#data.drop('Unnamed: 0',axis=1,inplace=True)"
      ],
      "metadata": {
        "id": "ebD-nWzsqTyy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.info()"
      ],
      "metadata": {
        "id": "DP319EI9qWnY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(10,6))\n",
        "plt.scatter(x=data['longitude'],y=data['latitude'])\n",
        "plt.title(\"Distribution of commodities\",size=16)"
      ],
      "metadata": {
        "id": "bVCtNYiqqev2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##By setting alpha=0.1, we can see high density areas. When alpha=0.1, the plotted elements (such as points or areas) are mostly transparent, making it easier to distinguish regions with high density because they will appear darker due to overlapping points."
      ],
      "metadata": {
        "id": "veH6lBwzq-uS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(10,6))\n",
        "plt.scatter(x=data['longitude'],y=data['latitude'],alpha=0.1)\n",
        "plt.title(\"Distribution of commodities\",size=16)"
      ],
      "metadata": {
        "id": "a4vBkKbeq3qm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This plot visualizes the geographical distribution of commodities, with each point representing a location and its size indicating the quantity of the commodity at that location.the legend provides a key for interpreting the colors used in the plot."
      ],
      "metadata": {
        "id": "EDGwowKxzBA0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The level of transparency (alpha) of the data points affects the visibility of overlapping points. Higher transparency allows you to see through overlapping points and observe patterns more clearly, while lower transparency may obscure details in densely populated areas."
      ],
      "metadata": {
        "id": "2q3N44kT0-bU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        " this code snippet generates a scatter plot visualizing the distribution of prices across geographical locations, with each point representing a location and its size indicating the price at that location. The color of each point represents the price value, with the color bar providing a reference for interpreting the price range"
      ],
      "metadata": {
        "id": "b_r9wWFl1eyD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(12,12))\n",
        "\n",
        "plt.scatter(x=data['longitude'],y=data['latitude'],alpha=0.5,s=data['price']/30,\n",
        "            cmap=plt.get_cmap(\"jet\"),zorder=1,label='price')\n",
        "plt.colorbar()\n",
        "plt.title(\"Distribution of prices\",size=16)\n",
        "plt.legend()"
      ],
      "metadata": {
        "id": "yKZpUZnWyP4q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "From above plot we can infer that,\n",
        "\n",
        "\n",
        "*   commodity prices are much related to location\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "bx6-OXcj3tIC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**SELECTION OF FEATURES**"
      ],
      "metadata": {
        "id": "i1dDFJdrl2Jv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "selected_features = ['date', 'commodity', 'price', 'longitude', 'latitude', 'market']\n",
        "\n",
        "# Filter the data based on selected features\n",
        "filtered_data = df[selected_features]\n",
        "\n",
        "# Filter the data to include only dates from 2023 to 2024\n",
        "filtered_data = filtered_data[(df['date'] >= '2023-07-01') & (df['date'] <= '2024-02-31')]\n",
        "\n",
        "# Define the specific commodities you want to include\n",
        "specific_commodities = ['Maize (new harvest)', 'Beans','Cowpeas']  # Replace with your specific commodities\n",
        "\n",
        "# Filter the data to include only the specific commodities\n",
        "filtered_data = filtered_data[filtered_data['commodity'].isin(specific_commodities)]\n",
        "\n",
        "# Display the filtered data\n",
        "filtered_data"
      ],
      "metadata": {
        "id": "W6-AzcoDl7bQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.columns"
      ],
      "metadata": {
        "id": "P9Cqup_Wbhul"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = df[['date', 'admin1', 'admin2', 'market', 'latitude', 'longitude',\n",
        "       'category', 'commodity', 'unit', 'priceflag', 'pricetype', 'currency',\n",
        "       'price', 'usdprice']]\n",
        "df.head()"
      ],
      "metadata": {
        "id": "RMcbtSXtbrX8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.isnull().sum()"
      ],
      "metadata": {
        "id": "ICcsICpXb2t4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# checking for duplicated rows\n",
        "\n",
        "df.duplicated().sum()"
      ],
      "metadata": {
        "id": "m1SUI2mub703"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()"
      ],
      "metadata": {
        "id": "yWvfkzyscABF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "catvars = df.select_dtypes(include=['object']).columns\n",
        "numvars = df.select_dtypes(include = ['int32','int64','float32','float64']).columns\n",
        "\n",
        "catvars,numvars"
      ],
      "metadata": {
        "id": "F31sYio8cHbB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def uniquevals(col):\n",
        "    print(f'Details of the particular col {col} is : {df[col].unique()}')\n",
        "\n",
        "def valuecounts(col):\n",
        "    print(f'Valuecounts of the particular col {col} is : {df[col].value_counts()}')\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "for col in df.columns:\n",
        "    uniquevals(col)\n",
        "    print(\"-\"*75)"
      ],
      "metadata": {
        "id": "IaXTYb6uct2Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Exploratory Data Analysis"
      ],
      "metadata": {
        "id": "XsDV08VOh4Ju"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# viewing the distribution of the price column\n",
        "\n",
        "sn.displot(filtered_data['price'],color='red')"
      ],
      "metadata": {
        "id": "Dq9rUF3dh6qT"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}